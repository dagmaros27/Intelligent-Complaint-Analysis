{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c39eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup â€” Imports and Load Necessary Models/Files\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import pipeline\n",
    "\n",
    "# Paths\n",
    "VECTOR_STORE_DIR = \"../vector_store\"\n",
    "FAISS_INDEX_PATH = os.path.join(VECTOR_STORE_DIR, \"faiss_index.bin\")\n",
    "METADATA_CSV_PATH = \"../data/chunked_metadata.csv\"\n",
    "\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "# Load chunk metadata\n",
    "metadata_df = pd.read_csv(METADATA_CSV_PATH)\n",
    "\n",
    "# Load text generation pipeline (change model_name as per your choice)\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", max_length=256, do_sample=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d432e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Semantic Search Retriever\n",
    "\n",
    "def semantic_search(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform semantic search to retrieve top_k relevant chunks based on query.\n",
    "    \"\"\"\n",
    "    query_vector = embedding_model.encode([query])\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        if idx == -1 or idx >= len(metadata_df):\n",
    "            continue\n",
    "        row = metadata_df.iloc[idx]\n",
    "        results.append({\n",
    "            \"id\": row.get(\"id\", \"\"),\n",
    "            \"product\": row.get(\"product\", \"\"),\n",
    "            \"chunk_index\": row.get(\"chunk_index\", \"\"),\n",
    "            \"chunk_text\": row.get(\"chunk_text\", \"\"),\n",
    "            \"score\": dist\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f969482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context_chunks, question, max_chars=1000):\n",
    "    \"\"\"\n",
    "    Builds a prompt using a truncated version of the context to fit the LLM's input size.\n",
    "    \"\"\"\n",
    "    context_text = \"\"\n",
    "    total_chars = 0\n",
    "\n",
    "    for chunk in context_chunks:\n",
    "        if total_chars + len(chunk) > max_chars:\n",
    "            break\n",
    "        context_text += chunk + \"\\n\\n\"\n",
    "        total_chars += len(chunk)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a financial analyst assistant for CrediTrust.\\n\"\n",
    "        \"Your task is to answer questions about customer complaints.\\n\"\n",
    "        \"Use the following retrieved complaint excerpts to formulate your answer.\\n\"\n",
    "        \"If the context doesn't contain the answer, say: \\\"I don't have enough information.\\\"\\n\\n\"\n",
    "        f\"Context:\\n{context_text}\\n\"\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31a3c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Generate Answer from Prompt\n",
    "\n",
    "def generate_answer(prompt):\n",
    "    \"\"\"\n",
    "    Generate an answer from the prompt using the LLM text generation pipeline.\n",
    "    \"\"\"\n",
    "    # Generate full output including prompt\n",
    "    full_output = generator(prompt, max_new_tokens=150, do_sample=True)[0]['generated_text']\n",
    "\n",
    "    # Extract only the answer by removing the prompt part\n",
    "    answer = full_output[len(prompt):].strip()\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c2fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the retriever function\n",
    "\n",
    "def retrieve_relevant_chunks(question, top_k=5):\n",
    "    \"\"\"\n",
    "    Embeds the input question and retrieves top_k most relevant text chunks using FAISS.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_vector = model.encode([question])\n",
    "        distances, indices = index.search(query_vector, top_k)\n",
    "\n",
    "        retrieved = []\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            if idx == -1 or idx >= len(metadata_df):\n",
    "                continue\n",
    "            row = metadata_df.iloc[idx]\n",
    "            retrieved.append({\n",
    "                \"id\": row[\"id\"],\n",
    "                \"product\": row[\"product\"],\n",
    "                \"chunk_index\": row[\"chunk_index\"],\n",
    "                \"chunk_text\": row[\"chunk_text\"],\n",
    "                \"score\": dist\n",
    "            })\n",
    "\n",
    "        return retrieved\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving chunks: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fe98092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Generated Answer</th>\n",
       "      <th>Retrieved Sources</th>\n",
       "      <th>Quality Score</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are common issues with credit card fraud?</td>\n",
       "      <td>You may be surprised by this question, \"What i...</td>\n",
       "      <td>[subject deceptive billing practices improper ...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do customers describe their problems with ...</td>\n",
       "      <td>\"I don't know what to do about that. I don't h...</td>\n",
       "      <td>[ally bank has had consistent issues with acce...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there complaints about Buy Now, Pay Later ...</td>\n",
       "      <td>All new users are not able to view the purchas...</td>\n",
       "      <td>[ongoing payment situation with best buy my pa...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What complaints exist regarding personal loans?</td>\n",
       "      <td>The following are examples of customer complai...</td>\n",
       "      <td>[in xxxxxxxx i took out a 60000 installment lo...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What issues do customers face with money trans...</td>\n",
       "      <td>i have a small amount of money with my account...</td>\n",
       "      <td>[i own a xxxx xxxx xxxx xxxx xxxx xxxx a custo...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0     What are common issues with credit card fraud?   \n",
       "1  How do customers describe their problems with ...   \n",
       "2  Are there complaints about Buy Now, Pay Later ...   \n",
       "3    What complaints exist regarding personal loans?   \n",
       "4  What issues do customers face with money trans...   \n",
       "\n",
       "                                    Generated Answer  \\\n",
       "0  You may be surprised by this question, \"What i...   \n",
       "1  \"I don't know what to do about that. I don't h...   \n",
       "2  All new users are not able to view the purchas...   \n",
       "3  The following are examples of customer complai...   \n",
       "4  i have a small amount of money with my account...   \n",
       "\n",
       "                                   Retrieved Sources Quality Score Comments  \n",
       "0  [subject deceptive billing practices improper ...          None           \n",
       "1  [ally bank has had consistent issues with acce...          None           \n",
       "2  [ongoing payment situation with best buy my pa...          None           \n",
       "3  [in xxxxxxxx i took out a 60000 installment lo...          None           \n",
       "4  [i own a xxxx xxxx xxxx xxxx xxxx xxxx a custo...          None           "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Evaluate the RAG Pipeline\n",
    "\n",
    "# Sample evaluation questions\n",
    "sample_questions = [\n",
    "    \"What are common issues with credit card fraud?\",\n",
    "    \"How do customers describe their problems with savings accounts?\",\n",
    "    \"Are there complaints about Buy Now, Pay Later services?\",\n",
    "    \"What complaints exist regarding personal loans?\",\n",
    "    \"What issues do customers face with money transfers?\"\n",
    "]\n",
    "\n",
    "# Store evaluation results\n",
    "eval_results = []\n",
    "\n",
    "for question in sample_questions:\n",
    "    retrieved_chunks = retrieve_relevant_chunks(question, top_k=5)\n",
    "    \n",
    "    # Skip if no results retrieved\n",
    "    if not retrieved_chunks:\n",
    "        eval_results.append({\n",
    "            \"Question\": question,\n",
    "            \"Generated Answer\": \"No relevant context found.\",\n",
    "            \"Retrieved Sources\": [],\n",
    "            \"Quality Score\": None,\n",
    "            \"Comments\": \"No chunks retrieved.\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Extract chunk texts\n",
    "    context_chunks = [r[\"chunk_text\"] for r in retrieved_chunks]\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = build_prompt(context_chunks, question)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(prompt)\n",
    "    \n",
    "    # Include top 2 retrieved sources for context in eval\n",
    "    top_sources = context_chunks[:2]\n",
    "\n",
    "    eval_results.append({\n",
    "        \"Question\": question,\n",
    "        \"Generated Answer\": answer,\n",
    "        \"Retrieved Sources\": top_sources,\n",
    "        \"Quality Score\": None,  # To be filled manually\n",
    "        \"Comments\": \"\"\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "import pandas as pd\n",
    "eval_df = pd.DataFrame(eval_results)\n",
    "\n",
    "# Display preview\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12390432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty evaluation CSV file created: rag_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = [\"Question\", \"Generated Answer\", \"Retrieved Sources\", \"Quality Score\", \"Comments\"]\n",
    "eval_df = pd.DataFrame(columns=columns)\n",
    "eval_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "print(\"Empty evaluation CSV file created: rag_evaluation_results.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
